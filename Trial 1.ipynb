{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb928e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv_frame_0.png written!\n",
      "opencv_frame_1.png written!\n",
      "opencv_frame_2.png written!\n",
      "opencv_frame_3.png written!\n",
      "opencv_frame_4.png written!\n",
      "opencv_frame_5.png written!\n",
      "opencv_frame_6.png written!\n",
      "opencv_frame_7.png written!\n",
      "opencv_frame_8.png written!\n",
      "opencv_frame_9.png written!\n",
      "opencv_frame_10.png written!\n",
      "opencv_frame_11.png written!\n",
      "opencv_frame_12.png written!\n",
      "opencv_frame_13.png written!\n",
      "opencv_frame_14.png written!\n",
      "opencv_frame_15.png written!\n",
      "opencv_frame_16.png written!\n",
      "opencv_frame_17.png written!\n",
      "opencv_frame_18.png written!\n",
      "opencv_frame_19.png written!\n",
      "opencv_frame_20.png written!\n",
      "opencv_frame_21.png written!\n",
      "opencv_frame_22.png written!\n",
      "opencv_frame_23.png written!\n",
      "opencv_frame_24.png written!\n",
      "opencv_frame_25.png written!\n",
      "opencv_frame_26.png written!\n",
      "opencv_frame_27.png written!\n",
      "opencv_frame_28.png written!\n",
      "opencv_frame_29.png written!\n",
      "opencv_frame_30.png written!\n",
      "opencv_frame_31.png written!\n",
      "opencv_frame_32.png written!\n",
      "opencv_frame_33.png written!\n",
      "opencv_frame_34.png written!\n",
      "opencv_frame_35.png written!\n",
      "opencv_frame_36.png written!\n",
      "opencv_frame_37.png written!\n",
      "opencv_frame_38.png written!\n",
      "opencv_frame_39.png written!\n",
      "opencv_frame_40.png written!\n",
      "opencv_frame_41.png written!\n",
      "opencv_frame_42.png written!\n",
      "opencv_frame_43.png written!\n",
      "opencv_frame_44.png written!\n",
      "opencv_frame_45.png written!\n",
      "opencv_frame_46.png written!\n",
      "opencv_frame_47.png written!\n",
      "opencv_frame_48.png written!\n",
      "opencv_frame_49.png written!\n",
      "opencv_frame_50.png written!\n",
      "opencv_frame_51.png written!\n",
      "opencv_frame_52.png written!\n",
      "opencv_frame_53.png written!\n",
      "opencv_frame_54.png written!\n",
      "opencv_frame_55.png written!\n",
      "opencv_frame_56.png written!\n",
      "opencv_frame_57.png written!\n",
      "opencv_frame_58.png written!\n",
      "opencv_frame_59.png written!\n",
      "opencv_frame_60.png written!\n",
      "opencv_frame_61.png written!\n",
      "opencv_frame_62.png written!\n",
      "opencv_frame_63.png written!\n",
      "opencv_frame_64.png written!\n",
      "opencv_frame_65.png written!\n",
      "opencv_frame_66.png written!\n",
      "opencv_frame_67.png written!\n",
      "opencv_frame_68.png written!\n",
      "opencv_frame_69.png written!\n",
      "opencv_frame_70.png written!\n",
      "opencv_frame_71.png written!\n",
      "opencv_frame_72.png written!\n",
      "opencv_frame_73.png written!\n",
      "opencv_frame_74.png written!\n",
      "opencv_frame_75.png written!\n",
      "opencv_frame_76.png written!\n",
      "opencv_frame_77.png written!\n",
      "opencv_frame_78.png written!\n",
      "opencv_frame_79.png written!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"test\")\n",
    "img_counter = 0\n",
    "\n",
    "\n",
    "#Load a sample picture and learn how to recognize it\n",
    "ian_image = face_recognition.load_image_file(\"ian.jpg\")\n",
    "ian_face_encoding = face_recognition.face_encodings(ian_image)[0]\n",
    "\n",
    "known_face_encodings = [\n",
    "    ian_face_encoding,\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Ian Lagat\",\n",
    "]\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    \n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    rgb_frame = frame[:, :, ::-1]\n",
    "    \n",
    "    #Find all the faces and face encodings in the frame of video\n",
    "    face_locations=face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings=face_recognition.face_encodings(rgb_frame,face_locations)\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    #Loop through each face in this frame of video\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        # See if the face is a match for the known face(s)\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        name = \"Unknown\"\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # If a match was found in known_face_encodings, just use the first one.\n",
    "        #if True in matches:\n",
    "         #    first_match_index = matches.index(True)\n",
    "          #   name = known_face_names[first_match_index]\n",
    "\n",
    "        # Or instead, use the known face with the smallest distance to the new face\n",
    "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        \n",
    "        \n",
    "        #Capture screenshot when a face is detected\n",
    "        img_name = \"opencv_frame_{}.png\".format(img_counter)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        img_counter += 1\n",
    "        if matches[best_match_index]:\n",
    "            name = known_face_names[best_match_index]\n",
    "            \n",
    "            \n",
    "            \n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    #cv2.imshow('Video', frame)\n",
    "       \n",
    "    \n",
    "    if not ret:\n",
    "        print(\"failed to grab frame\")\n",
    "        break\n",
    "    cv2.imshow(\"test\", frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "'''\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_name = \"opencv_frame_{}.png\".format(img_counter)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        img_counter += 1\n",
    "'''\n",
    "cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72daaa33",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) C:\\b\\abs_74oeeuevib\\croots\\recipe\\opencv-suite_1664548340488\\work\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m ret, frame \u001b[38;5;241m=\u001b[39m video_capture\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     23\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m---> 25\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[43mfaceCascade\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaleFactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminNeighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminSize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Draw a rectangle around the faces\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x, y, w, h) \u001b[38;5;129;01min\u001b[39;00m faces:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) C:\\b\\abs_74oeeuevib\\croots\\recipe\\opencv-suite_1664548340488\\work\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import logging as log\n",
    "import datetime as dt\n",
    "from time import sleep\n",
    "\n",
    "cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "log.basicConfig(filename='webcam.log',level=log.INFO)\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "anterior = 0\n",
    "\n",
    "while True:\n",
    "    if not video_capture.isOpened():\n",
    "        print('Unable to load camera.')\n",
    "        sleep(5)\n",
    "        pass\n",
    "\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    if anterior != len(faces):\n",
    "        anterior = len(faces)\n",
    "        log.info(\"faces: \"+str(len(faces))+\" at \"+str(dt.datetime.now()))\n",
    "\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'): \n",
    "\n",
    "        check, frame = video_capture.read()\n",
    "        cv2.imshow(\"Capturing\", frame)\n",
    "        cv2.imwrite(filename='saved_img.jpg', img=frame)\n",
    "        video_capture.release()\n",
    "        img_new = cv2.imread('saved_img.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "        img_new = cv2.imshow(\"Captured Image\", img_new)\n",
    "        cv2.waitKey(1650)\n",
    "        print(\"Image Saved\")\n",
    "        print(\"Program End\")\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        break\n",
    "    elif cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Turning off camera.\")\n",
    "        video_capture.release()\n",
    "        print(\"Camera off.\")\n",
    "        print(\"Program ended.\")\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353702f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
